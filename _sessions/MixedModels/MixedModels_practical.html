<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Mixed Models</title>

<script src="MixedModels_practical_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="MixedModels_practical_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="MixedModels_practical_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="MixedModels_practical_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="MixedModels_practical_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="MixedModels_practical_files/navigation-1.1/tabsets.js"></script>
<link href="MixedModels_practical_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="MixedModels_practical_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="practical.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->





<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Mixed Models</h1>
<h3 class="subtitle"><em>Linear models with hierarchical data</em></h3>
<h4 class="author"><em><table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'>
<col width='10%'>
<col width='10%'>
<tr style="border:none">
<td style="display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none" nowrap>
<font style='font-style:normal'>Statistics with R</font><br> <a href='https://therbootcamp.github.io/SwR_2019Apr/'> <i class='fas fa-clock' style='font-size:.9em;' ></i> </a> <a href='https://therbootcamp.github.io'> <i class='fas fa-home' style='font-size:.9em;'></i> </a> <a href='mailto:therbootcamp@gmail.com'> <i class='fas fa-envelope' style='font-size: .9em;'></i> </a> <a href='https://www.linkedin.com/company/basel-r-bootcamp/'> <i class='fab fa-linkedin' style='font-size: .9em;'></i> </a> <a href='https://therbootcamp.github.io'> <font style='font-style:normal'>Basel R Bootcamp</font> </a>
</td>
<td style="width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none">
<img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
</td>
</tr>
</table></em></h4>

</div>


<p align="center" width="100%">
<img src="image/rottentomatoes.png" alt="Trulli" style="width:100%;height:280px"> <br> <font style="font-size:10px">from <a href="https://www.rottentomatoes.com/">rottentomatoes.com</a></font>
</p>
<div id="section" class="section level1 tabset">
<h1></h1>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p>In this practical you’ll practice “mixed effects modeling” with the <code>lme4</code>, <code>sjstats</code>, <code>stats</code>, and <code>pbkrtest</code> packages.</p>
<p>By the end of this practical you will know how to:</p>
<ol style="list-style-type: decimal">
<li>Run mixed effects models in R.</li>
<li>Extract p-values for fixed effects.</li>
<li>Select the appropriate random effects structure.</li>
<li>Specify crossed vs. nested random effects.</li>
<li>Extract variance components and compute the explained variance and intra-class correlation</li>
<li>Visualize your linear mixed effects model.</li>
<li>Run a generalized mixed effects model.</li>
</ol>
</div>
<div id="tasks" class="section level2">
<h2>Tasks</h2>
<div id="a---setup" class="section level3">
<h3>A - Setup</h3>
<ol style="list-style-type: decimal">
<li><p>Open your <code>BaselRBootcamp</code> R project. It should already have the folders <code>1_Data</code> and <code>2_Code</code>. Make sure that the data files listed in the <code>Datasets</code> section above are in your <code>1_Data</code> folder</p></li>
<li><p>Open a new R script. At the top of the script, using comments, write your name and the date. Save it as a new file called <code>MixedModels_practical.R</code> in the <code>2_Code</code> folder.</p></li>
<li><p>Using <code>library()</code> load the <code>tidyverse</code>, <code>lme4</code>, and <code>sjstats</code> packages (if you don’t have them, you’ll need to install them with <code>install.packages()</code>)!</p></li>
</ol>
<pre class="r"><code># Load packages necessary for this script
library(tidyverse)
library(lme4)
library(sjstats)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Using the following template, load the <code>tomatometer.csv</code> and <code>schools.csv</code> data into R and store it as a new object called <code>tom</code> and <code>schools</code>, respectively (Hint: Don’t type the path directly! Use the “tab” completion!).</li>
</ol>
<pre class="r"><code># Load tomatometer.csv from the 1_Data folder
XX &lt;- read_csv(file = &quot;XX/XX&quot;)

# Load school.csv from the 1_Data folder
XX &lt;- read_csv(file = &quot;XX/XX&quot;)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Take a look at the first few rows of the datasets by printing them to the console.</li>
</ol>
<pre class="r"><code># Print the object(s)
XXX
XXX</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Use the the <code>summary()</code> function to print more details on the columns of the datasets.</li>
</ol>
<pre class="r"><code>summary(XXX)
summary(XXX)</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>Use the <code>View()</code> function to view the entire dataframe(s) in a new window.</li>
</ol>
<pre class="r"><code>View(XXX)
View(XXX)</code></pre>
</div>
<div id="b---running-a-linear-mixed-effects-model" class="section level3">
<h3>B - Running a Linear Mixed Effects Model</h3>
<p>In the first part of this practical we will work with the <code>tom</code> data example from the slides and test the effect of a person’s <code>State</code> (“Sober” vs. “Drunk”) on his or her <code>Tomatometer</code> rating.</p>
<ol style="list-style-type: decimal">
<li>Run fixed effects only model predicting <code>Tomatometer</code> with <code>State</code> and save the result as <code>FE_mod</code>. Then inspect the results.</li>
</ol>
<pre class="r"><code># Use lm, as lmer only works if at least one random effect is specified
FE_mod &lt;- glm(formula = XXX ~ XXX, 
              data = XXX)

# Inspect the results
summary(XXX)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Currently “Drunk” is taken as base state, so the intercept shows the mean at state “Drunk” and the slope shows how much lower the ratings in <code>State == &quot;Sober&quot;</code> are. To obtain a more intuitive model with “Sober” as the base level, <em>coerce</em> the <code>State</code> variable into a factor and set the levels. Do this by running the following code.</li>
</ol>
<pre class="r"><code># Coerce the State variable into a factor
tom &lt;- tom %&gt;%
  mutate(State = factor(State, levels = c(&quot;Sober&quot;, &quot;Drunk&quot;)))</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Now rerun your model from task B1.</p></li>
<li><p>Compare the model output of B3 with the one you obtained in B1. How did the coefficients change? Why?</p></li>
<li><p>Now run a model with by-subjects random intercepts (subjects identifiers are stored in the <code>ID</code> variable). <em>Hint</em>: Random effects are specified in parenthesis in the formula in the following way <code>(</code><a href="https://en.wikipedia.org/wiki/Design_matrix">design_matrix</a><code>|grouping_variable)</code>. <strong>Note</strong>: The <code>REML = FALSE</code> in the model specification tells R to fit the model using maximum likelihood (ML), rather than restricted maximal likelihood (REML; for more information on this in a technical approach see <a href="https://projecteuclid.org/euclid.cbms/1462106081">here</a> and <a href="http://www.stats.net.au/Maths_REML_manual.pdf">here</a>, for a less technical approach see <a href="https://en.wikipedia.org/wiki/Restricted_maximum_likelihood">here</a>). This will later be important for certain model comparisons that only work if the model was fitted using ML.</p></li>
</ol>
<pre class="r"><code># Mixed effects model with by-subject random intercepts
subj_RI_mod &lt;- lmer(formula = XXX ~ XXX +           # These are the fixed effects
                    (1|XXX),              # These are the random effects
                    data = XXX,           # Specify the data used
                    REML = FALSE)</code></pre>
<ol start="6" style="list-style-type: decimal">
<li><p>Using <code>summary()</code>, inspect the results of the mixed effects model.</p></li>
<li><p>Did the effect of <code>State</code> change, now that you incorporated the random effects? Can you find out what did change from the model outputs?</p></li>
<li><p>Sometimes it is useful to extract the estimates from the model output (e.g., so we don’t have to manually type them, which would be error prone). Extract the fixed effects from <code>subj_RI_mod</code> using the <code>fixef()</code> function.</p></li>
</ol>
<pre class="r"><code># Print fixed effects from subj_RI_mod
fixef(XXX)</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>Now extract the random effects from <code>subj_RI_mod</code> using the <code>ranef()</code> function.</li>
</ol>
<pre class="r"><code># Print random effects from subj_RI_mod
ranef(XXX)</code></pre>
<ol start="10" style="list-style-type: decimal">
<li>Expand your mixed effects model from task B4 by adding by-subjects slopes. <em>Hint</em>: add the <code>State</code> variable to the left side of the bar <code>|</code> in the random effects part of the formula.</li>
</ol>
<pre class="r"><code># Mixed effects model with by-subject random intercepts and slopes
subj_RI_RS_mod &lt;- lmer(formula = XXX ~ XXX +          # These are the fixed effects
                      (XXX|XXX),            # These are the random effects
                      data = XXX,           # Specify the data used
                      REML = FALSE)</code></pre>
<ol start="11" style="list-style-type: decimal">
<li><p>Compare the outputs of the fixed effects only model, of the by-subjects random intercepts model, and of the by-subjects random intercepts and slopes model. Do this by applying the <code>summary()</code> function to each of the objects. Did the coefficients change? Why not? What did change?</p></li>
<li><p>Each movie was rated in both states, so there is also a repetition in the items, which again leads to a violation of the independence assumption. To account for this, expand the model from task B9 by adding by-movie random intercepts and slopes. <em>Note</em>: The additional argument specifies a different optimizer such that the model converges.</p></li>
</ol>
<pre class="r"><code># Mixed effects model with by-subject and by-movie random intercepts and slopes
max_mod &lt;- lmer(formula = XXX ~ XXX +           # These are the fixed effects
               (XXX|XXX) + (XXX|XXX), # These are the random effects
               data = XXX,            # Specify the data used
               REML = FALSE,
               control = lmerControl(optimizer = &quot;bobyqa&quot;)) # use a different optimizer
                                                            # to avoid non convergence</code></pre>
<ol start="13" style="list-style-type: decimal">
<li><p>The <code>converge_ok()</code> function from the <code>sjstats</code> package let’s you check whether the model converged or not. If the functions returns <code>TRUE</code> you’re good. Test whether <code>max_mod</code> converged.</p></li>
<li><p><code>max_mod</code> is now the <em>maximal model justified by the design</em>. What does this mean? Why is it a good thing to specify this model?</p></li>
<li><p>Compare the results with those of the earlier models by looking at their summary outputs using <code>summary()</code>.</p></li>
<li><p>What changed with the increasingly complex random effects structure?</p></li>
</ol>
</div>
<div id="c---r2" class="section level3">
<h3>C - <span class="math inline">\(R^2\)</span></h3>
<p>When fitting statistical models, we are often interested in how much systematic variation they can capture. In linear (mixed effects) models this is the <span class="math inline">\(R^2\)</span> value (the coefficient of determination); for generalized (mixed effects) models, we can compute pseudo <span class="math inline">\(R^2\)</span> values.</p>
<ol style="list-style-type: decimal">
<li><p>We will use the <code>r2()</code> function from the <code>sjstats</code> package to compute <span class="math inline">\(R^2\)</span> values. Look at the help menu of the function to get an overview of what models you can use it for.</p></li>
<li><p>Compute the <span class="math inline">\(R^2\)</span> of the maximal model.</p></li>
<li><p>What does the output of the last task mean? What is the marginal <span class="math inline">\(R^2\)</span> and what is the conditional <span class="math inline">\(R^2\)</span>?</p></li>
<li><p>Compare the <span class="math inline">\(R^2\)</span> values of <code>max_mod</code> with those of less complex models. Are the changes large? Which <span class="math inline">\(R^2\)</span> values changed?</p></li>
</ol>
</div>
<div id="d---visualize-your-model" class="section level3">
<h3>D - Visualize Your Model</h3>
<p>It is often useful to visualize your model’s output. Run the code below to extract coefficients from <code>max_mod</code> and plot the data along with a few sample lines to visualize the variability in the slopes and intercepts. As plotting is not the topic of this bootcamp we don’t have time to go into details here. If you are interested in learning more about plotting, there are many books and tutorials about it, and we also cover it in the <em>R for Data Science</em> bootcamp.</p>
<ol style="list-style-type: decimal">
<li>Run the following code to visualize your <code>max_mod</code> data.</li>
</ol>
<pre class="r"><code># extract fixed effects
m_line &lt;- fixef(max_mod)

# extract random effects
ranefs &lt;- ranef(max_mod)
predicted &lt;- tibble(
  intercept = ranefs$ID[,1] + fixef(max_mod)[1],
  slope = ranefs$ID[,2] + fixef(max_mod)[2])

# randomly draw 15 subjects to plot the fitted lines
rand15 &lt;- sample(1:nrow(predicted), 15)

LMM_plot &lt;- ggplot(tom, aes(State, Tomatometer)) +
  geom_point(colour= &quot;#606061&quot;, alpha = .15, size = 2.5)+
  geom_segment(aes(x = 1, y = intercept, xend = 2, yend = intercept + slope),
               data = predicted %&gt;% slice(rand15), colour = &quot;#EA4B68&quot;, size = 1.5,
               alpha = .8) +
  geom_segment(aes(x = 1, y = m_line[1], xend = 2, yend = sum(m_line)),
               colour = &quot;black&quot;, size = 2, alpha = 1) +
  theme(axis.title.x = element_text(vjust = -1),
        axis.title.y = element_text(vjust = 1)) +
  theme_bw() +
  ylim(0, 100) +
  theme(
    strip.text = element_text(size = 12, face = &quot;bold&quot;),
    axis.text = element_text(size = 16),
    axis.title = element_text(size = 18,face = &quot;bold&quot;)
  )

LMM_plot</code></pre>
</div>
<div id="e---computing-p-values-for-fixed-effects" class="section level3">
<h3>E - Computing p-Values for Fixed Effects</h3>
<p>As you probably noticed, the <code>lmer()</code> summary output does not include p-values. This is not because the authors of <code>lme4</code> were lazy, but because how to best compute p-values for mixed effects models is a still ongoing discussion. However, several possibilities exist of how to test whether a variable is a significant predictor (i.e., a significant fixed effect). We will look at a couple of them.</p>
<div id="likelihood-ratio-test" class="section level4">
<h4>Likelihood Ratio Test</h4>
<p>One possibility to obtain p-values is by conducting a likelihood ratio test (<a href="https://en.wikipedia.org/wiki/Likelihood-ratio_test">LRT</a>). In an LRT, the model is fitted once with and once without the fixed effect of interest, all else being equal. These two models are then compared in using the LRT. This test only works if the models were fit using maximum likelihood (ML) estimation, rather than restricted maximum likelihood (REML) estimation, which is why we used <code>REML = FALSE</code> when fitting the mixed effects models.</p>
<ol style="list-style-type: decimal">
<li>First, fit an intercept only model (<code>IO_mod</code>) where you predict <code>Tomatometer</code> with only the grand mean, and the by-subjects and by-movies random intercepts.</li>
</ol>
<pre class="r"><code># Intercept only mixed effects model with by-subject and by-movie random intercepts
IO_mod &lt;- lmer(formula = XXX ~ 1 +         # There are no fixed effects so add 1 to fit the intercept
              (1|XXX) + (1|XXX), # These are the random effects
              data = XXX,        # Specify the data used
              REML = FALSE)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>Look at the model output using <code>summary()</code>.</p></li>
<li><p>Now fit the same model as in task E1, but add the <code>State</code> variables. Save the output as <code>RI_mod</code>. Note that we again need to use another optimizer to avoid convergence problems (You don’t need to worry about this now, you can use the code template below).</p></li>
</ol>
<pre class="r"><code># Intercept only mixed effects model with by-subject and by-movie random intercepts
RI_mod &lt;- lmer(formula = XXX ~ XXX +         # The fixed effects
              (1|XXX) + (1|XXX),   # These are the random effects
              data = XXX,          # Specify the data used
              REML = FALSE,
              control = lmerControl(optimizer = &quot;bobyqa&quot;)) # use a different optimizer
                                                            # to avoid non convergence</code></pre>
<ol start="4" style="list-style-type: decimal">
<li><p>Check whether <code>RI_mod</code> converged using the <code>converge_ok()</code> function.</p></li>
<li><p>Perform an LRT using the <code>anova()</code> function, by entering both model outputs (<code>IO_mod</code>, and <code>RI_mod</code>) as arguments. Is the difference significant? What does this mean?</p></li>
</ol>
<pre class="r"><code># Perform an LRT using the anova() function
anova(XXX, XXX)</code></pre>
</div>
<div id="confidence-intervals" class="section level4">
<h4>Confidence Intervals</h4>
<p>This method is not a formal way of testing significance, as it does not produce a p-value. In this method, confidence intervals are obtained and checked if they include zero. If they don’t, this is interpreted as a significant result.</p>
<ol start="6" style="list-style-type: decimal">
<li>We can obtain confidence intervals for our fixed effects using the <code>confint()</code> function of the <code>lme4</code> package. Do this by entering <code>max_mod</code> into the <code>confint()</code> function.</li>
</ol>
<pre class="r"><code># Compute confidence intervals for the fixed effects
ci_mod &lt;- confint(XXX)</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Print the <code>ci_mod</code> object. Do the confidence intervals you obtained match the conclusion you drew from inspecting the t-values and the LRT?</li>
</ol>
</div>
<div id="other-tests" class="section level4">
<h4>Other Tests</h4>
<ol start="8" style="list-style-type: decimal">
<li>Another way of obtaining p-values with the t-statistic and a <a href="https://en.wikipedia.org/wiki/Wald_test">Wald test</a> by using the <code>p_value()</code> function of the <code>sjstats</code> package. Enter <code>max_mod</code> to the <code>p_value()</code> function.</li>
</ol>
<pre class="r"><code># Compute p-values for the fixed effects
p_value(fit = XXX)</code></pre>
<ol start="9" style="list-style-type: decimal">
<li><p>As this test may not be appropriate for mixed effects models, we can extend the <code>p_value()</code> function with an additional argument, <code>p.kr = TRUE</code>. Then the function will compute p-values based on conditional F-tests with <a href="https://www.jstatsoft.org/article/view/v059i09">Kenward-Roger approximation</a> for the degrees of freedom. Repeat the previous task by extending the function with <code>p.kr = TRUE</code>.</p></li>
<li><p>Compare the output of the tasks E8 and E9 Did things change? The reason why not is that the assumptions were all satisfied as the data was simulated with these assumptions, but with noisier real life data this may look different.</p></li>
</ol>
</div>
</div>
<div id="f---determining-the-significance-of-random-effects-model-selection" class="section level3">
<h3>F - Determining the “Significance” of Random Effects (Model Selection)</h3>
<p>You may remember the <em>keep it maximal</em> principle, which states that you should always specify the maximal random effects structure justified by the design to guard against type I error inflation (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/">Barr, Levy, Scheepers, &amp; Tily, 2013</a>). However, the maximal model may come with a loss of power to detect fixed effects and it may make sense to select which random effects structure to use (<a href="https://www.sciencedirect.com/science/article/pii/S0749596X17300013">Matuschek, Kliegl, Vasishth, Baayen, &amp; Bates, 2017</a>). To express it with the words of Matuschek and Colleagues: “[A] parsimonious mixed model […] containing only variance components supported by the data improves the balance between Type I error and power” (p. 305). To select which model to use, we will use LRTs.</p>
<p>When performing this LRT, we cannot use the usual alpha limit of .05. To see why, read the following quote from <a href="https://www.sciencedirect.com/science/article/pii/S0749596X17300013">Matuschek and colleagues (2017; p. 308)</a></p>
<blockquote>
<p>Within the context of model selection, it is important to resist the reflex of choosing <span class="math inline">\(\alpha_{LRT} = 0.05\)</span>. The <span class="math inline">\(\alpha_{LRT}\)</span> cannot be interpreted as the ‘‘expected model-selection Type I error-rate” but rather as the relative weight of model complexity and goodness-of-fit. For example, choosing <span class="math inline">\(\alpha_{LRT} = 0\)</span>, an infinite penalty on the model complexity is implied and consequently the minimal model is always chosen as the best, irrespective of the evidence provided by the data. Choosing <span class="math inline">\(\alpha_{LRT} = 1\)</span> implies an infinite penalty on the goodness-of-fit, and the maximal model is always chosen as the best. Therefore, choosing <span class="math inline">\(\alpha_{LRT} = 0.05\)</span> may imply an overly strong penalty on the model complexity and hence select a reduced model even if data favor a more complex one.</p>
</blockquote>
<p>We will follow their example and use <span class="math inline">\(\alpha_{LRT} = 0.2\)</span>. As the <code>anova()</code> function uses <span class="math inline">\(\alpha = 0.05\)</span> we will have to implement this procedure ourselves.</p>
<ol style="list-style-type: decimal">
<li>First, we have to fit the model whose complexity is one step lower compared to the maximal model. Think about which model this would be and write down the answer as a comment in your script. Don’t cheat by looking at the next task!</li>
</ol>
<pre class="r"><code># This is just a placeholder to increase the space to the next task to make it 
# easier to not cheat.

# There is nothing to see here...

# Just a random sidenote (which is actually very interesting so you may want to
# to read on, even if this kind of defies the purpose of this part to prevent you from
# looking at the answers first; so consider first completing the task and then reading
# the random but somehow terribly interesting sidenote):
#     Did you know that the reason why R uses the arrow &quot;&lt;-&quot; as assignment
#     operator is because it is based on S, which in turn is based on APL?
#     Now apparently, APL was designed on a specific keyboard that had a
#     &quot;&lt;-&quot; key and there was no &quot;==&quot; implemented to test equality. So equality
#     was tested using &quot;=&quot; and &quot;&lt;-&quot; was chosen as assignment operator
#     (info obtained from this blogpost: https://colinfay.me/r-assignment/).</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>The answer to the last task is that you can constrain the correlation of the random intercepts and random slopes to zero. Use the double bar <code>||</code> in the random effects structure, that is <code>(design_matrix||grouping_variable)</code> to do this. Fit the maximal model but constrain the correlations to zero.</li>
</ol>
<pre class="r"><code># Constrained mixed effects model with by-subject and by-movie random intercepts and slopes
con_mod &lt;- lmer(formula = XXX ~ XXX +             # These are the fixed effects
               (XXX||XXX) + (XXX||XXX), # These are the random effects
               data = XXX,              # Specify the data used
               REML = FALSE,
               control = lmerControl(optimizer = &quot;bobyqa&quot;)) # use a different optimizer
                                                            # to avoid non convergence</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Check whether the model converged using <code>converge_ok()</code>.</p></li>
<li><p>This model didn’t converge. This can happen and it’s not always easy to find out how to get the model to converge. One way would be to use different Bayesian methods with the <code>rstanarm</code> package. This is rather advanced and we will ignore it for now, but should this happen to you in your work you may not want to interpret this model.</p></li>
<li><p>Now let’s prepare the setup for the LRT. The difference in the deviances of two models (defined as negative two times the log-likelihood) approximately follows a <span class="math inline">\(\chi^2\)</span> distribution. Therefore we can test the significance by testing whether the <span class="math inline">\(\chi^2\)</span> value is larger than a threshold value. To do this we set up our <span class="math inline">\(\alpha_{LRT}\)</span> and derive the threshold value. Do this by running the following code.</p></li>
</ol>
<pre class="r"><code>alpha &lt;- .2 # set up the alpha value
st &lt;- qchisq(1 - alpha, df = 2) # derive the critical value above which the difference
                                # is significant. We have two degrees of freedom because
                                # the constrained model has two more degrees of freedom </code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Now we can compute the difference in the deviances by subtracting the deviance from the more complex model from the constrained model. Extract the deviances from the two models using the <code>deviance()</code> function from the <code>stats</code> package and save the difference as <code>d_diff</code>.</li>
</ol>
<pre class="r"><code>d_diff &lt;- deviance(XXX) - deviance(XXX)</code></pre>
<ol start="7" style="list-style-type: decimal">
<li><p>Test whether the difference in deviance is large enough to be classified as a significant deviance according to our <span class="math inline">\(\alpha_{LRT}\)</span> level. <em>Hint</em>: Test whether <code>d_diff</code> is larger than the significance threshold <code>st</code>.</p></li>
<li><p>The output of the previous task was <code>FALSE</code>. What does that mean? Do you keep the maximal model in this case? What would it mean if the result were <code>TRUE</code>, how would your next steps look?</p></li>
</ol>
</div>
<div id="g---residual-variances" class="section level3">
<h3>G - Residual Variances</h3>
<ol style="list-style-type: decimal">
<li><p>We may be interested in knowing the residual variance (the error; denoted as within group variance in the output), and the random effects variances. Extract this information from the maximal model output by using the <code>re_var()</code> function from the <code>sjstats</code> package.</p></li>
<li><p>Look at the output from the last task. Are the different variances large? Is the within group variance or the between group variance larger and how do you interpret this information?</p></li>
</ol>
</div>
<div id="x---challenges" class="section level3">
<h3>X - Challenges</h3>
<div id="more-on-p-values-for-fixed-effects-parametric-bootstrap" class="section level4">
<h4>More on p-Values for Fixed Effects: Parametric Bootstrap</h4>
<p>Another test of the significance of fixed effects, and the one you should prefer in an uncertain case (i.e., if p-values are on the border of your alpha-level), is to use parametric bootstrap, where, many times, data is resampled with replacement and then the model is fitted again, to obtain an empirical distribution of the effect or parameter of interest. The drawback of this technique is that it can take rather long.</p>
<ol style="list-style-type: decimal">
<li>For linear mixed effects models (fit using <code>lmer()</code>) you can use the <code>PBmodcomp()</code> function from the <code>pbkrtest</code> package. Check out the help function of <code>PBmodcomp()</code> like this.</li>
</ol>
<pre class="r"><code>?PBmodcomp</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Now use the <code>PBmodcomp()</code> function to get p-values for the model. You will have to specify a less complex model against which to test. Use <code>IO_mod</code> for this. Also, because this procedure can take rather long, only use 100 simulations.</li>
</ol>
<pre class="r"><code># perform parametric bootstrap
pb_mod &lt;- PBmodcomp(largeModel = XXX, 
                    smallModel = XXX, 
                    nsim = XXX)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Print the <code>pb_mod</code> object and inspect the results. Are the results different from the other tests you’ve performed before? How does the p-value from the parametric bootstrap test compare to the one obtained from the likelihood test?</li>
</ol>
</div>
<div id="intra-class-correlation" class="section level4">
<h4>Intra-Class Correlation</h4>
<p>The intra-class correlation (ICC) is “the proportion of the variance explained by the grouping structure in the population” (Hox 2002, p.15). It is calculated by dividing the between-group variance by the sum of the within-group and the between-group variance (i.e., the total variance).</p>
<ol style="list-style-type: decimal">
<li><p>Compute the ICC of the maximal model using the <code>icc()</code> function from the <code>sjstats</code> package.</p></li>
<li><p>Take a look at the output. Did you notice the warning? This is because the ICC cannot be interpreted in the same way for random slopes and intercepts models. Add the argument <code>adjusted = TRUE</code> to your ICC call to take care of the warning.</p></li>
<li><p>Check the <code>icc()</code> help page to understand what happened now that you added the <code>adjusted = TRUE</code> argument.</p></li>
<li><p>Often, the ICC is computed on the intercept only model with random intercepts. In task C1. you have already fitted this model and saved it as <code>IO_mod</code>. Compute the ICC form this model. <em>Hint</em>: no need to use the <code>adjusted</code> argument, as no random slopes are involved.</p></li>
<li><p>Now do the same for the <code>RI_mod</code>, that differs from the <code>IO_mod</code> you’ve just used only in that it also contains the fixed effect.</p></li>
<li><p>Compare the outputs of the last two tasks. Did things change? Think about what these changes mean.</p></li>
</ol>
</div>
<div id="crossed-versus-nested-random-effects" class="section level4">
<h4>Crossed Versus Nested Random Effects</h4>
<p>So far we only considered crossed random effects. Now we will also look at data with <em>nested random effects</em>, where every level of a nested factor only appears within a single level of a higher order factor. A popular example is the case of classes within schools. Every class is only part of a single school and thus class is nested within schools.</p>
<p>To know whether random effects are crossed or nested, you usually need to know the design, as the structure is often not obvious from the factor levels. For example, even though class may be nested in schools, the classes may be numbered from 1 to the number of classes in that school. So school 1 may have classes 1 to 10, and school 2 may have classes from 1 to 6. Obviously class 1 of school 1 is not the same as class 1 of school 2. However, what is obvious for you is not obvious for R. It doesn’t know about the concept of schools and classes, so you have to tell it whether these factors are nested or not, using the appropriate syntax in the formula. Now consider the case where the classes are nested in schools, but numbered from 1 to total number of classes, that is, such that every class has a unique label. In this case it does not matter what structure you specify.</p>
<ol style="list-style-type: decimal">
<li>Now we will work with the <code>school</code> data set you have already loaded in section A. Using the <code>table()</code> function, create a cross table of school and class. (<em>Hint</em>: You’ll have to enter the variables separately.)</li>
</ol>
<pre class="r"><code>table(XXX, XXX)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>Fit a mixed effects model predicting extraversion (<code>extra</code>) with openness (<code>open</code>) and the social score (<code>social</code>) with random intercepts for classes nested in school and save it as <code>hier_mod</code>. <em>Hint</em>: The nested random effects structure is specified with the following syntax <code>(1|higher_level_variable/lower_level_variable)</code>.</p></li>
<li><p>Did the model converge? Check with <code>converge_ok()</code></p></li>
<li><p>Inspect the model output using <code>summary()</code>.</p></li>
<li><p>Now fit the same model but with crossed random intercepts as in the sections before, rather than with nested random intercepts. Save the output as <code>cross_mod</code>.</p></li>
<li><p>Check whether the model converged.</p></li>
<li><p>Inspect the output using the <code>summary()</code> function.</p></li>
<li><p>Did the results change compared to the ones for the nested random effects structure?</p></li>
</ol>
</div>
<div id="more-random-effects-selection" class="section level4">
<h4>More Random Effects Selection</h4>
<ol style="list-style-type: decimal">
<li><p>In task D6 you found out that the constrained model with correlations between random effects set to zero is not significantly worse than the maximal model. Thus, if you were testing a confirmatory hypothesis, you should choose this model rather than the maximal model. What we didn’t do in section F is to proceed with our backward selection procedure. This is now your task. Fit a model with by-subject random intercepts and slopes, but without their correlation, and with by-movie random intercepts.</p></li>
<li><p>Now perform the procedure of Section D. to evaluate which of the two models to keep. <em>Note</em>: You will have to set the <code>df</code> argument in the <code>qchisq()</code> function to <code>df = 1</code> because these two models only differ in one degree of freedom.</p></li>
<li><p>What is your conclusion which model to keep and work with?</p></li>
</ol>
</div>
<div id="generalized-linear-mixed-effects-models" class="section level4">
<h4>Generalized Linear Mixed Effects Models</h4>
<ol style="list-style-type: decimal">
<li><p>Now we will look at generalized linear mixed effects model. Load the <code>cancer_remission.csv</code> data into R and save it as <code>cr</code>.</p></li>
<li><p>Take a look at the data. It is a subset of simulated data from <a href="https://stats.idre.ucla.edu/">UCLA Institute for Digital Research and Education Search this website</a>.</p></li>
<li><p>Predict cancer remission (<code>remission</code>) by the cancer stage (<code>CancerStage</code>), the length of the patients stay (<code>LengthofStay</code>), the doctors experience (<code>Experience</code>), and by specifying by doctor (<code>DID</code>) random intercepts. Use the <code>glmer</code> function with <code>family = binomial</code> to do this. Also, use the “bobyqa” optimizer as in some examples before.</p></li>
<li><p>Did the model converge?</p></li>
<li><p>Inspect the model output.</p></li>
<li><p>Extract the <span class="math inline">\(R^2\)</span> value for this model, once using the <code>r2()</code> and once using the <code>cod()</code> function. Are the results the same? Find out what the differences are by checking the help pages.</p></li>
</ol>
<p><strong>Note</strong>: Running and interpreting generalized linear mixed effects models can be quite challenging and we don’t have the time here to cover them in more detail. You can check out this <a href="https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-generalized-linear-mixed-models/">tutorial</a> or the references listed under resources if you want to learn more about this.</p>
</div>
</div>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<pre class="r"><code># load packages
library(lme4)
library(sjstats)

# look at sleepstudy data contained in lme4
head(sleepstudy)

# look at describtion of sleepstudy
?sleepstudy

# fixed effects only model predicting the reaction time
# from the number of days with sleep deprivation
sleep_FE &lt;- glm(formula = Reaction ~ Days, data = sleepstudy)

# inspect model
summary(sleep_FE)

# intercept only model mixed effects model
sleep_IO &lt;- lmer(formula = Reaction ~ 1 + (1|Subject),
                 data = sleepstudy,
                 REML = FALSE)

# inspect model
summary(sleep_IO)

# run random interceptes model
sleep_RI &lt;- lmer(formula = Reaction ~ Days + (1|Subject),
                 data = sleepstudy,
                 REML = FALSE)

# inspect output
summary(sleep_RI)

# check whether model converged
converge_ok(sleep_RI)

# get p_values for fixed effects using Kenward-Roger approximation
p_value(sleep_RI, p.kr = TRUE)

# alternatively, get p-value using anova() function
anova(sleep_IO, sleep_RI)

# run mixed effects model without correlations between random effects parameters
sleep_nc &lt;- lmer(formula = Reaction ~ Days + (Days||Subject),
                 data = sleepstudy,
                 REML = FALSE)

# check whether the model converged
converge_ok(sleep_nc)

# check model output
summary(sleep_nc)

# run maximal model (by-subjects random slopes and intercepts)
sleep_max &lt;- lmer(formula = Reaction ~ Days + (Days|Subject),
                  data = sleepstudy,
                  REML = FALSE)

# check whether the model converged
converge_ok(sleep_max)

# check model output
summary(sleep_max)

### select the random effects structure

# set alpha to .2
alpha &lt;- .2

# derive the critical value above which the difference is significant.
st1 &lt;- qchisq(1 - alpha, df = 1)

# get the difference in deviance between the two models
d_diff &lt;- deviance(sleep_nc) - deviance(sleep_max)

# Test whether this difference is large enough to be considered significant
d_diff &gt; st1

# correlation is not necessary. Now test whether the random slopes are necessary
d_diff &lt;- deviance(sleep_RI) - deviance(sleep_nc)

# Test whether this difference is large enough to be considered significant
d_diff &gt; st1 # -&gt; keep sleep_nc model

# compute r-squared
r2(sleep_nc)

# compute icc
icc(sleep_nc, adjusted = TRUE)

### Visualize Model

# extract fixed effects
m_line &lt;- fixef(sleep_nc)

# extract random effects
ranefs &lt;- ranef(sleep_nc)
predicted &lt;- tibble(
  intercept = ranefs$Subject[,1] + fixef(sleep_nc)[1],
  slope = ranefs$Subject[,2] + fixef(sleep_nc)[2])

# randomly draw 10 subjects to plot the fitted lines
rand10 &lt;- sample(1:nrow(predicted), 10)

LMM_plot &lt;- ggplot(sleepstudy, aes(Days, Reaction)) +
  geom_point(colour= &quot;#606061&quot;, alpha = .15, size = 2.5)+
  geom_segment(aes(x = 0, y = intercept, xend = 9, yend = intercept + slope * 9),
               data = predicted %&gt;% slice(rand10), colour = &quot;#EA4B68&quot;, size = 1.5,
               alpha = .8) +
  geom_segment(aes(x = 0, y = m_line[1], xend = 9, yend = m_line[1] + 9 * m_line[2]),
               colour = &quot;black&quot;, size = 2, alpha = 1) +
  theme(axis.title.x = element_text(vjust = -1),
        axis.title.y = element_text(vjust = 1)) +
  theme_bw() +
  theme(
    strip.text = element_text(size = 12, face = &quot;bold&quot;),
    axis.text = element_text(size = 16),
    axis.title = element_text(size = 18,face = &quot;bold&quot;)
  )

LMM_plot</code></pre>
</div>
<div id="datasets" class="section level2">
<h2>Datasets</h2>
<table>
<thead>
<tr class="header">
<th align="left">File</th>
<th align="left">Rows</th>
<th align="left">Columns</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/SwR_2019Apr/master/1_Data/tomatometer.csv?token=AIFo1JUJrMd9LfEcBY6u9ZhqlCcMaTvGks5csP1AwA%3D%3D">tomatometer.csv</a></td>
<td align="left">5995</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/SwR_2019Apr/master/1_Data/schools.csv?token=AZQb9mdlio2aNiTgfaddDHxpENKWm3Hhks5cmQ9jwA%3D%3D">schools.csv</a></td>
<td align="left">1200</td>
<td align="left">7</td>
</tr>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/SwR_2019Apr/master/1_Data/cancer_remission.csv?token=AZQb9ic1yv1-UdOtMITu0HyaW1xRMdV9ks5cmQ-bwA%3D%3D">cancer_remission.csv</a></td>
<td align="left">8525</td>
<td align="left">5</td>
</tr>
</tbody>
</table>
<p>The <em>tomatometer.csv</em> dataset contains tomatometer ratings from 200 raters who each rated 15 movies, once while they were sober and once while they were drunk.</p>
<p>The <em>schools.csv</em> dataset contains ratings of extraversion, openness to experience, agreeableness, and a social score of 1200 students from different classes of 6 different schools.</p>
<p>The <em>cancer_remission.csv</em> dataset contains data on lung cancer remission from patients nested within doctors</p>
<div id="tomatometer.csv" class="section level4">
<h4>tomatometer.csv</h4>
<table>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ID</td>
<td align="left">Participant id code</td>
</tr>
<tr class="even">
<td align="left">Movie</td>
<td align="left">Movie ID from M1 to M15</td>
</tr>
<tr class="odd">
<td align="left">State</td>
<td align="left">the state in which the rating was done (“sober”, or “drunk”)</td>
</tr>
<tr class="even">
<td align="left">Tomatometer</td>
<td align="left">tomatometer rating from 0 to 100</td>
</tr>
</tbody>
</table>
</div>
<div id="schools.csv" class="section level4">
<h4>schools.csv</h4>
<table>
<colgroup>
<col width="26%" />
<col width="73%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">id</td>
<td align="left">pupil id</td>
</tr>
<tr class="even">
<td align="left">extra</td>
<td align="left">extraversion rating of pupil from 0 to 100</td>
</tr>
<tr class="odd">
<td align="left">open</td>
<td align="left">openness to experience rating of pupil from 0 to 100</td>
</tr>
<tr class="even">
<td align="left">agree</td>
<td align="left">agreeableness rating of pupil from 0 to 100</td>
</tr>
<tr class="odd">
<td align="left">social</td>
<td align="left">social score of pupil</td>
</tr>
<tr class="even">
<td align="left">class</td>
<td align="left">the class a pupil is in (nested under school; levels “a”, “b”, “c”, and “d”)</td>
</tr>
<tr class="odd">
<td align="left">school</td>
<td align="left">the school a pupil / class is in (levels “I”, “II”, “III”, “IV”)</td>
</tr>
</tbody>
</table>
</div>
<div id="cancer_remission.csv" class="section level4">
<h4>cancer_remission.csv</h4>
<table>
<colgroup>
<col width="26%" />
<col width="73%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">remission</td>
<td align="left">whether the cancer is in remission (0 = No, 1 = Yes)</td>
</tr>
<tr class="even">
<td align="left">CancerStage</td>
<td align="left">four different cancer stages (levels “I”, “II”, “III”, “IV”)</td>
</tr>
<tr class="odd">
<td align="left">LengthofStay</td>
<td align="left">how long a participant stayed in hospital (score ranging from 1 to 10)</td>
</tr>
<tr class="even">
<td align="left">Experience</td>
<td align="left">experience of the doctor (ranging from 7 to 29, probably years of experience)</td>
</tr>
<tr class="odd">
<td align="left">DID</td>
<td align="left">doctor id</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="functions" class="section level2">
<h2>Functions</h2>
<div id="packages" class="section level3">
<h3>Packages</h3>
<table>
<thead>
<tr class="header">
<th align="left">Package</th>
<th align="left">Installation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>tidyverse</code></td>
<td align="left"><code>install.packages(&quot;tidyverse&quot;)</code></td>
</tr>
<tr class="even">
<td align="left"><code>lme4</code></td>
<td align="left"><code>install.packages(&quot;lme4&quot;)</code></td>
</tr>
<tr class="odd">
<td align="left"><code>sjstats</code></td>
<td align="left"><code>install.packages(&quot;sjstats&quot;)</code></td>
</tr>
<tr class="even">
<td align="left"><code>pbkrtest</code></td>
<td align="left"><code>install.packages(&quot;pbkrtest&quot;)</code></td>
</tr>
</tbody>
</table>
</div>
<div id="functions-1" class="section level3">
<h3>Functions</h3>
<table>
<colgroup>
<col width="7%" />
<col width="12%" />
<col width="80%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Function</th>
<th align="left">Package</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>lmer</code></td>
<td align="left"><code>lme4</code></td>
<td align="left">Fit a linear mixed effects model</td>
</tr>
<tr class="even">
<td align="left"><code>glmer</code></td>
<td align="left"><code>lme4</code></td>
<td align="left">Fit a generalized linear mixed effects model</td>
</tr>
<tr class="odd">
<td align="left"><code>fixef</code></td>
<td align="left"><code>lme4</code></td>
<td align="left">Extract fixed effects coefficients from lmer or glmer output</td>
</tr>
<tr class="even">
<td align="left"><code>ranef</code></td>
<td align="left"><code>lme4</code></td>
<td align="left">Extract random effects coefficients from lmer or glmer output</td>
</tr>
<tr class="odd">
<td align="left"><code>anova</code></td>
<td align="left"><code>stats</code></td>
<td align="left">Generic function to run (in this case) a likelihood ratio test</td>
</tr>
<tr class="even">
<td align="left"><code>confint</code></td>
<td align="left"><code>stats</code></td>
<td align="left">Compute confidence intervals for various statistical outputs</td>
</tr>
<tr class="odd">
<td align="left"><code>deviance</code></td>
<td align="left"><code>stats</code></td>
<td align="left">Extract the deviance of various statistical outputs</td>
</tr>
<tr class="even">
<td align="left"><code>qchisq</code></td>
<td align="left"><code>stats</code></td>
<td align="left">Quantile function of the <span class="math inline">\(\chi^2\)</span> distribution to get critical <span class="math inline">\(\chi^2\)</span> values</td>
</tr>
<tr class="odd">
<td align="left"><code>PBmodcomp</code></td>
<td align="left"><code>pbkrtest</code></td>
<td align="left">Perform parametric bootstrap to obtain p-values from linear mixed effects models</td>
</tr>
<tr class="even">
<td align="left"><code>converge_ok</code></td>
<td align="left"><code>sjstats</code></td>
<td align="left">Test whether a model converged or not (some warnings produced by lmer and glmer may be informative but not necessarily mean you need to worry, so this function is a good proxy to use. If it yields <code>FALSE</code> you may want to investigate things and try to take measures to improve your model)</td>
</tr>
<tr class="odd">
<td align="left"><code>p_value</code></td>
<td align="left"><code>sjstats</code></td>
<td align="left">Compute p-values for fixed effects of mixed effects models using Wald’s test or conditional F-tests with Kenward-Roger approximation for the degrees of freedom</td>
</tr>
<tr class="even">
<td align="left"><code>r2</code></td>
<td align="left"><code>sjstats</code></td>
<td align="left">Extract <span class="math inline">\(R^2\)</span> value from (generalized) linear (mixed effects) model outputs</td>
</tr>
<tr class="odd">
<td align="left"><code>icc</code></td>
<td align="left"><code>sjstats</code></td>
<td align="left">Compute ICCs from (generalized) linear mixed effects model outputs</td>
</tr>
<tr class="even">
<td align="left"><code>re_var</code></td>
<td align="left"><code>sjstats</code></td>
<td align="left">Extract random effects and residual variances from (generalized) linear mixed effects model outputs</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="resources" class="section level2">
<h2>Resources</h2>
<div id="vignettes" class="section level3">
<h3>Vignettes</h3>
<p><a href="https://strengejacke.github.io/sjstats/">sjstats webpage</a></p>
<p><a href="https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf">lme4 vignette</a></p>
</div>
<div id="further-reading" class="section level3">
<h3>Further Reading</h3>
<p>A nice and non-technical introduction to mixed effects models can be found in a chapter titled <a href="http://davidkellen.org/wp-content/uploads/2017/04/introduction-mixed-models.pdf"><strong>An introduction to linear mixed modeling in experimental psychology</strong></a> by <strong>Henrik Singmann</strong> and <strong>David Kellen</strong>.</p>
<p>A more technical introduction can be found in the mixed effects models chapter of <a href="https://projecteuclid.org/euclid.cbms/1462106081"><strong>Analysis of Longitudinal and Cluster-Correlated Data</strong></a> by <strong>Nan Laird</strong>.</p>
<p>A freely available tutorial on mixed effects models can be found <a href="https://www.ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">here</a>.</p>
<p>An introduction to <span class="math inline">\(R^2\)</span> and ICC in mixed effects model can be found in the article <a href="https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0213">The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded</a> by <strong>Shinichi Nakagawa</strong>, <strong>Paul Johnson</strong>, and <strong>Holger Schielzeth</strong>.</p>
<p>A rather technical introduction to mixed effects model with <code>lme4</code> is given in <a href="https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf"><strong>Fitting Linear Mixed-Effects Models Using lme4</strong></a> by <strong>Douglas Bates</strong>, <strong>Martin Mächler</strong>, <strong>Benjamin Bolker</strong>, and <strong>Steven Walker</strong>.</p>
<p>One of the classic introductions to regression models, including mixed effects models, is <a href="https://www.cambridge.org/ch/academic/subjects/statistics-probability/statistical-theory-and-methods/data-analysis-using-regression-and-multilevelhierarchical-models?format=PB&amp;isbn=9780521686891"><strong>Data Analysis Using Regression and Multilevel/Hierarchical Models</strong></a> by <strong>Andrew Gelman</strong> and <strong>Jennifer Hill</strong>.</p>
<p>Another great introduction to regression, including mixed effects models, is <a href="https://xcelab.net/rm/statistical-rethinking/"><strong>Statistical Rethinking</strong></a> by <strong>Richard McElreath</strong>.</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
